# R4DS Excercises Ch.12-13
## Nabil Lachgar


# Problem 12.2.1

# 1 
* table 1: the columns are each variables and rows are observations
* table 2: each row is one observation (population or case)
* table 3: each row is one observation where population and case variables become "rate"
* table 4: data split into two tables (one for population and one for rates) 

# 2
* t2pop <- table2 %>% filter(type == 'population')
* names(t2pop)[names(t2pop) == 'count'] <- 'population'
* t2tb <- table2 %>% filter(type == 'cases')
* names(t2tb)[names(t2tb) == 'count'] <- 'cases'
* table2sum <- merge(t2pop, t2tb, by = c( 'country', 'year'))
* t2final <- table2sum %>% mutate(rate = (cases/population)*10000)
* t2final
- Spread() would be more efficient

* table4rates <- table4a
* names(table4rates)[names(table4rates) == '1999'] <- '1999 cases'
* names(table4rates)[names(table4rates) == '2000'] <- '2000 cases'
* table4rates$rate1999 <- (table4a$`1999`/table4b$`1999`)*10000
* table4rates$rate2000 <- (table4a$`2000`/table4b$`2000`)*10000
* table4rates

- Data output was different for both
- Table2 is easier to transition to tidy

# 3

table2 %>% spread(type, count)
?spread
ggplot(table2 %>% spread(type, count), aes(year, cases)) + 
  geom_line(aes(group = country), colour = "grey50") + 
  geom_point(aes(colour = country))

# Problem 12.3.3

# 1
stocks <- tibble(
year   = c(2015, 2015, 2016, 2016),
half  = c(   1,    2,     1,    2),
return = c(1.88, 0.59, 0.92, 0.17))
stocks %>% 
  spread(year, return) %>% 
  gather("year", "return", `2015`:`2016`)
stocks
- convert() argument switches year and half columns when run

# 2
* We need to add `` around years:
table4a %>% 
  gather(`1999`, `2000`, key = "year", value = "cases")

# 3
people <- tribble(
  ~name,             ~key,    ~value,
  #-----------------|--------|------
  "Phillip Woods1",   "age",       45,
  "Phillip Woods2",   "height",   186,
  "Phillip Woods3",   "age",       50,
  "Jessica Cordero1", "age",       37,
  "Jessica Cordero2", "height",   156)
spread(people, key, value)

* personID would be better since names aren't unique

# 4
preg <- tribble(
  ~pregnant, ~male, ~female,
  "yes",     NA,    10,
  "no",      20,    12)
preg %>% 
  gather(male,female, key = "gender", value = "value") %>% 
  spread(pregnant, value)

* We need to use the gather() and spread() functions
* the variables are a count of pregnant and non-pregnant people

# 5  
table3 %>% 
  separate(rate, into = c("cases", "population"))

## Problem 12.4.3

# 1  
    ?separate()
    * extra: when a character vector has too many pieces
    * fill: when a character vector is missing pieces

# 2
?unite()
?separate()
* remove: gets rid of original columns
* To keep original columns, set to false
* extra & fill can be used to confirm original format of columns

# 3
?separate()
?extract()
* Extract() requires the groups to match regex

# Problem 12.5.1

# 1 
* spread() adjusts formatting of the columns/rows
* complete() adds rows that didin't initially exist with NA values
* fill() fills in blank NAs that exist in the data with a new value

# 2 
?fill - fills in NAs from above or below where the NA values are 

# Problem 12.6.1

# 1: NA means data doesn't exist while 0 means that no people were diagnosed

# 2 
who %>%
gather(code, value, new_sp_m014:newrel_f65, na.rm = TRUE) %>% 
  mutate(code = stringr::str_replace(code, "newrel", "new_rel")) %>%
  separate(code, c("new", "var", "sexage")) %>% 
  select(-new, -iso2, -iso3) %>% 
  separate(sexage, c("sex", "age"), sep = 1)
* new_rel rows get a 'too few values' error 

# 3
* who %>% group_by(country) %>% 
  summarise(iso2s = n_distinct(iso2)) %>% 
  filter(iso2s > 1)
* who %>% group_by(country) %>% 
  summarise(iso3s = n_distinct(iso3)) %>% 
  filter(iso3s > 1)

* It is a 1:1 match since no country has distinct iso2 or iso3

# 4
who %>%
  gather(code, value, new_sp_m014:newrel_f65, na.rm = TRUE) %>% 
  mutate(code = stringr::str_replace(code, "newrel", "new_rel")) %>%
  separate(code, c("new", "var", "sexage")) %>% 
  select(-new, -iso2, -iso3) %>% 
  separate(sexage, c("sex", "age"), sep = 1) %>% 
  filter(year > 1994) %>% 
  group_by(country, year, sex) %>% 
  summarise(cases = sum(value)) %>% 
  ggplot(aes(x = year, y = cases, group = country, fill = country)) +
  geom_bar(stat = "identity", show.legend = FALSE, position = "dodge") +
  facet_grid(.~sex)

* there is too much data to visualize
  


# Chapter 13

# Problem 13.2.1 

# 1: nycflights13 for dep/dest
* Join to airports in order to get longitude and latitude coordinates

# 2: airports joins to weather on faa = origin

# 3: Could also have a link to dest as well as origin (even if called origin we could conceptually join to dest)

# 4: We could create a 'Days' table 



# Problem 13.3.1

# 1 
flights %>% mutate(surkey = row_number())

# 2 
install.packages("Lahman")
library(Lahman)
install.packages("babynames")
library(babynames)
install.packages("nasaweather")
library(nasaweather)
install.packages("fueleconomy")
library(fueleconomy)

* count() function should show primary keys
Batting %>% count(playerID, yearID, stint) %>% filter(n > 1)
babynames::babynames %>% count(year, sex, name) %>% filter(nn > 1)
nasaweather::atmos %>% count(lat, long, year, month) %>% filter(n > 1)
fueleconomy::vehicles %>% count(id) %>% filter(n>1)
diamonds # No primary key, each diamond is its own observations

# Problem 13.4.6

# 1
* install.packages("maps")
* flightDelays <- flights %>% group_by(dest) %>% summarise(avgDelay = mean(dep_delay, na.rm = TRUE))

airports %>%
  left_join(flightDelays, c("faa" = "dest")) %>% 
  select(faa, lat, lon, avgDelay) %>% 
 filter(lon > -140 & !is.na(avgDelay))  %>%  #Ignore alaska & hawaii so graph looks better, make sure avgDelay exists
ggplot( aes(lon, lat, size = avgDelay, color = avgDelay)) +
  borders("state") +
  geom_point() +
  coord_quickmap()
  
# 2 
flights %>% 
  left_join(airports, c('dest' = 'faa')) %>% 
  left_join(airports, c('origin' = 'faa'))

# 3
?planes
flights %>% 
  left_join(planes, by = 'tailnum') %>% 
  mutate(planeAge = 2017-year.y) %>% 
  group_by(planeAge) %>% 
  summarise(avgDelay = mean(dep_delay, na.rm = TRUE), totalFlights = n()) %>% 
  filter(totalFlights > 100) %>% 
  ggplot(aes(x = planeAge, y = avgDelay)) + 
  geom_point() +
  geom_smooth()

* no significant correlation
* 1st 10 years - correlation between plane age and delay time
* next 10 years - delays drop back down and data 

flights %>% 
  left_join(planes, by = 'tailnum') %>% 
  mutate(planeAge = 2017-year.y) %>% 
  filter(planeAge > 60) %>% 
  select(tailnum, planeAge, origin, dest)
* 61 year old plane made 21 flights from JFK to SFO

# 4 
fsum <- flights %>% 
  left_join(weather, c('origin', 'year', 'month', 'day', 'hour')) %>% 
  group_by(origin, year, month, day, hour, temp, dewp, humid, wind_dir, wind_speed, wind_gust, precip, pressure, visib) %>% 
  summarise(avgDelay = mean(dep_delay, na.rm = TRUE)) %>% 
  
  group_by(visib) %>% summarise(avgDelay2 = mean(avgDelay, na.rm = TRUE))
 
* change the x axis variable to determine strongest correlation   
* temp: some correlation    
* dewp: no correlation
* humid: no correlation
* wind_dir: 50 - 200 values have higher delays
* wind_speed: higher wind speed predicts greater delay
* wind_gust: higher wind gusts predict greater delay
* precip: no correlation
* pressure: small correlation
* visib: lower visibility yields greater delay

# 5 
weather %>% 
  filter(month == 6 & day == 13) %>% 
  left_join(flights, c('origin', 'year', 'month', 'day', 'hour')) %>% 
  group_by(hour, origin) %>% 
  summarise(avgDelay = mean(dep_delay, na.rm = TRUE)) %>% 
  ggplot(aes(x = hour, y = avgDelay, group = origin, color = origin)) +
  geom_line()

* many storms in midwest and southwest

# Problem 13.5.1
# 1
flights %>% 
  filter(is.na(tailnum))
* Flights with missing tail numbers have no dep_time
tmpflights <- flights %>% 
  select(tailnumf = tailnum) 

flights %>% 
  anti_join(planes, c('tailnum' = 'tailnum')) %>% 
  count(carrier, sort = TRUE) %>% 
  View
flights
* The flights are mostly MQ or AA

# 2

flights %>% 
  inner_join(flights %>% 
  count(tailnum) %>% 
  filter(n > 100), 'tailnum')

# 3
fueleconomy::common
fueleconomy::vehicles

?common
#Don't know which year the models dataset came out so don't have reference for 'years' meaning column
# So code will have cars 'n' value repeat across years

vehicles %>% 
  inner_join(common, by = c('make', 'model')) %>% 
  arrange(desc(n)) %>% 
  View

# 4 
flights %>% 
  group_by(year, month, day) %>% 
  summarise(avgDelay = mean(dep_delay, na.rm = TRUE)) %>% 
  ungroup() %>% 
  mutate(primaryKey = row_number()) %>% 
  mutate(TwoDayLagVal = (lead(avgDelay) + avgDelay)/2) %>% 
  arrange(desc(TwoDayLagVal))

# 5
anti_join(flights, airports, by = c("dest" = "faa"))
* Flights that match airports have their observations dropped

anti_join(airports, flights, by = c("faa" = "dest"))
* Airports without flights listed in the flights table

# 6
flights %>% 
  group_by(tailnum) %>% 
  summarise(carriers = n_distinct(carrier)) %>% 
  filter( carriers > 1)
* Few planes with several carriers
* tailnumbers in in PQ and AT
